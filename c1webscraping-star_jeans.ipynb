{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import requests\n",
    "import math\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url do site\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "# dicionario que diz para i end point que quem faz a requisicao e um chorme (Browser)\n",
    "headers ={''}\n",
    "headers = headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "# Requisita essa url do servidor do site H&M\n",
    "page = requests.get( url, headers=headers )\n",
    "\n",
    "# Product lista das primeiras coletas id, cat, name, price\n",
    "soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "# Toda minha vitrine\n",
    "products = soup.find('ul', class_= 'products-listing small')\n",
    "\n",
    "# Todos meu produtos da vitrine e sua cat, onde filtro todas que preciso\n",
    "product_list = products.find_all('article', class_ = 'hm-product-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================= product =========================================\n",
    "\n",
    "# Product_id\n",
    "product_list[0].get('data-articlecode')\n",
    "product_id = [i.get('data-articlecode') for i in product_list]\n",
    "\n",
    "# Product_category\n",
    "product_list[0].get('data-category')\n",
    "product_category = [i.get('data-category') for i in product_list]\n",
    "\n",
    "# product_name\n",
    "product_list = products.find_all('a', class_= 'item-link' )\n",
    "product_list[0].get('title')\n",
    "product_name = [i.get('title') for i in product_list]\n",
    "\n",
    "# product_price\n",
    "product_list = products.find_all('span', class_='price regular')\n",
    "product_price = [i.get_text() for i in product_list]\n",
    "\n",
    "\n",
    "# Criando o data frame\n",
    "data = pd.DataFrame([ product_id, product_name, product_category, product_price ]).T\n",
    "#colunas do DataFrame\n",
    "data.columns = ['product_id', 'product_name', 'product_category', 'product_price']\n",
    "\n",
    "# scrapy datetime\n",
    "data['scrapy_datetime'] = datetime.now().strftime( '%Y-%m-%d %H:%M:%S:')\n",
    "# plotar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coleta para um Unico Produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www2.hm.com/en_us/productpage.0985159001.html'\n",
    "\n",
    "# dicionario que diz para i end point que quem faz a requisicao e um chorme (Browser)\n",
    "headers ={''}\n",
    "headers = headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "# Requisita essa url do servidor do site H&M\n",
    "page = requests.get( url, headers=headers )\n",
    "\n",
    "# ================  One Product =================================\n",
    "\n",
    "# para acesar a pagina html do page , objeto da classe request\n",
    "page.text\n",
    "# Parametro de entrada para o beautifulsoup\n",
    "soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "# ========================== Color Name ===============================\n",
    "# Coletar a cor color_name\n",
    "product_list = soup.find_all('a', class_='filter-option miniature')\n",
    "product_color = [i.get('data-color') for i in product_list]\n",
    "\n",
    "# product_id\n",
    "product_id = [i.get('data-articlecode') for i in product_list]\n",
    "\n",
    "# Ccriando o data frame\n",
    "df_color = pd.DataFrame([product_id, product_color]).T\n",
    "df_color.columns = ['product_id', 'color_name']\n",
    "\n",
    "# # generate style id+ color id\n",
    "df_color['style_id'] = df_color['product_id'].apply( lambda x: x[:-3] )\n",
    "df_color['color_id'] = df_color['product_id'].apply( lambda x: x[-3:] )\n",
    "\n",
    "# =============================== Caategory =======================================\n",
    "\n",
    "# Encontre todos os elementos que representam os produtos\n",
    "product_elements = soup.find_all('div', class_='content pdp-text pdp-content')\n",
    "\n",
    "# Inicialize uma lista para armazenar as informações de todos os produtos\n",
    "all_products_info = []\n",
    "\n",
    "for product_element in product_elements:\n",
    "    product_info = {}\n",
    "    \n",
    "    # Extrair informações específicas para cada produto\n",
    "    fit_element = product_element.find('dt', string='Fit')\n",
    "    if fit_element:\n",
    "        fit = fit_element.find_next('dd').text.strip()\n",
    "        product_info['Fit'] = fit\n",
    "        \n",
    "    size_element = product_element.find('dt', string='Size')\n",
    "    if size_element:\n",
    "        size = size_element.find_next('dd').text.strip()\n",
    "        product_info['Size'] = size    \n",
    "    \n",
    "    composition_element = product_element.find('h3', string='Composition')\n",
    "    if composition_element:\n",
    "        composition = composition_element.find_next('p').text.strip()\n",
    "        product_info['Composition'] = composition\n",
    "       \n",
    "    pocket_lining_element = product_element.find('h4', string='Pocket lining')\n",
    "    if pocket_lining_element:\n",
    "        pocket_lining = pocket_lining_element.find_next('p').text.strip()\n",
    "        product_info['Pocket lining'] = pocket_lining\n",
    "        \n",
    "    article_number_element = product_element.find('div', string=re.compile(r'Article number\\d+'))\n",
    "    if article_number_element:\n",
    "        article_number_text = article_number_element.text.strip()\n",
    "        article_number = re.search(r'\\d+', article_number_text).group()\n",
    "        product_info['Article number'] = article_number    \n",
    "        \n",
    "    # Adicionar as informações do produto à lista\n",
    "    all_products_info.append(product_info);\n",
    "\n",
    "# criar data frame \n",
    "df_composition = pd.DataFrame(all_products_info)\n",
    "\n",
    "df_composition['style_id'] = df_composition['Article number'].apply( lambda x: x[:-3])\n",
    "df_composition['color_id'] = df_composition['Article number'].apply( lambda x: x[-3:])\n",
    "\n",
    "# ========================== df_color + df_composition ================================== \n",
    "data_sku = pd.merge( df_color, df_composition[['style_id', 'Fit', 'Composition']], how='left', on='style_id');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requisicao para toda a vitrine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www2.hm.com/en_us/productpage.1130309005.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www2.hm.com/en_us/productpage.0979945001.html\n",
      "https://www2.hm.com/en_us/productpage.0985159001.html\n",
      "https://www2.hm.com/en_us/productpage.1008549001.html\n",
      "https://www2.hm.com/en_us/productpage.1130309004.html\n",
      "https://www2.hm.com/en_us/productpage.1024256001.html\n",
      "https://www2.hm.com/en_us/productpage.0979945003.html\n",
      "https://www2.hm.com/en_us/productpage.1182102002.html\n",
      "https://www2.hm.com/en_us/productpage.1008549005.html\n",
      "https://www2.hm.com/en_us/productpage.1159764002.html\n",
      "https://www2.hm.com/en_us/productpage.1024256011.html\n",
      "https://www2.hm.com/en_us/productpage.1202825001.html\n",
      "https://www2.hm.com/en_us/productpage.1024256006.html\n",
      "https://www2.hm.com/en_us/productpage.1096385001.html\n",
      "https://www2.hm.com/en_us/productpage.1130309007.html\n",
      "https://www2.hm.com/en_us/productpage.1008549006.html\n",
      "https://www2.hm.com/en_us/productpage.1182102001.html\n",
      "https://www2.hm.com/en_us/productpage.1008549029.html\n",
      "https://www2.hm.com/en_us/productpage.1024256005.html\n",
      "https://www2.hm.com/en_us/productpage.0875105036.html\n",
      "https://www2.hm.com/en_us/productpage.1008110019.html\n",
      "https://www2.hm.com/en_us/productpage.0979945039.html\n",
      "https://www2.hm.com/en_us/productpage.1024711008.html\n",
      "https://www2.hm.com/en_us/productpage.1166422001.html\n",
      "https://www2.hm.com/en_us/productpage.1158786001.html\n",
      "https://www2.hm.com/en_us/productpage.0690449022.html\n",
      "https://www2.hm.com/en_us/productpage.0985159004.html\n",
      "https://www2.hm.com/en_us/productpage.0979945038.html\n",
      "https://www2.hm.com/en_us/productpage.1139723008.html\n",
      "https://www2.hm.com/en_us/productpage.1024711006.html\n",
      "https://www2.hm.com/en_us/productpage.0811993070.html\n",
      "https://www2.hm.com/en_us/productpage.0875105037.html\n",
      "https://www2.hm.com/en_us/productpage.0690449051.html\n",
      "https://www2.hm.com/en_us/productpage.0811993036.html\n",
      "https://www2.hm.com/en_us/productpage.1139723007.html\n",
      "https://www2.hm.com/en_us/productpage.1096385002.html\n"
     ]
    }
   ],
   "source": [
    "# dicionario que diz para i end point que quem faz a requisicao e um chorme (Browser)\n",
    "headers ={''}\n",
    "headers = headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# cria a lista vazia para colocar as col que nao tenho aqui coletada caso meu novo prod tenha alguma caracteristca que nao peguei no promeiro\n",
    "aux = []\n",
    "\n",
    "cols = ['Article number','Composition','Fit','Pocket lining','Size','color_id','style_id']\n",
    "df_patter = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range( len( data ) ):\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] + '.html'\n",
    "    print(url)\n",
    "    # Requisita essa url do servidor do site H&M\n",
    "    page = requests.get( url, headers=headers )\n",
    "    \n",
    "    # Parametro de entrada para o beautifulsoup\n",
    "    soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "    # ========================== Color Name ===============================\n",
    "    # Coletar a cor color_name\n",
    "    product_list = soup.find_all('a', class_='filter-option miniature')\n",
    "    product_color = [i.get('data-color') for i in product_list]\n",
    "\n",
    "    # product_id\n",
    "    product_id = [i.get('data-articlecode') for i in product_list]\n",
    "\n",
    "    #    Ccriando o data frame\n",
    "    df_color = pd.DataFrame([product_id, product_color]).T\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "\n",
    "    # # generate style id+ color id\n",
    "    df_color['style_id'] = df_color['product_id'].apply( lambda x: x[:-3] )\n",
    "    df_color['color_id'] = df_color['product_id'].apply( lambda x: x[-3:] )\n",
    "\n",
    "    # =============================== Caategory =======================================\n",
    "\n",
    "    # Encontrei todos os elementos que representam os produtos\n",
    "    product_elements = soup.find_all('div', class_='content pdp-text pdp-content')\n",
    "\n",
    "    # Inicializei uma lista para armazenar as informações de todos os produtos\n",
    "    all_products_info = []\n",
    "\n",
    "    for product_element in product_elements:\n",
    "        product_info = {}\n",
    "    \n",
    "        # Extrair informações específicas para cada produto\n",
    "        fit_element = product_element.find('dt', string='Fit')\n",
    "        if fit_element:\n",
    "            fit = fit_element.find_next('dd').text.strip()\n",
    "            product_info['Fit'] = fit\n",
    "        \n",
    "        size_element = product_element.find('dt', string='Size')\n",
    "        if size_element:\n",
    "            size = size_element.find_next('dd').text.strip()\n",
    "            product_info['Size'] = size    \n",
    "    \n",
    "        composition_element = product_element.find('h3', string='Composition')\n",
    "        if composition_element:\n",
    "            composition = composition_element.find_next('p').text.strip()\n",
    "            product_info['Composition'] = composition\n",
    "       \n",
    "        pocket_lining_element = product_element.find('h4', string='Pocket lining')\n",
    "        if pocket_lining_element:\n",
    "            pocket_lining = pocket_lining_element.find_next('p').text.strip()\n",
    "            product_info['Pocket lining'] = pocket_lining\n",
    "        \n",
    "        article_number_element = product_element.find('div', string=re.compile(r'Article number\\d+'))\n",
    "        if article_number_element:\n",
    "            article_number_text = article_number_element.text.strip()\n",
    "            article_number = re.search(r'\\d+', article_number_text).group()\n",
    "            product_info['Article number'] = article_number    \n",
    "        \n",
    "        # Adicionar as informações do produto à lista\n",
    "        all_products_info.append(product_info)\n",
    "        \n",
    "    # Garante the same number o columns    \n",
    "    df_composition = pd.concat([ df_patter, df_composition], axis=0)\n",
    "    \n",
    "    # criar data frame \n",
    "    df_composition = pd.DataFrame(all_products_info)\n",
    "\n",
    "    df_composition['style_id'] = df_composition['Article number'].apply( lambda x: x[:-3])\n",
    "    df_composition['color_id'] = df_composition['Article number'].apply( lambda x: x[-3:])\n",
    "    \n",
    "    # guardo aqui minhas col de composition e concateno a lista somando\n",
    "    aux = aux + df_composition.columns.tolist()\n",
    "\n",
    "    # ========================== df_color + df_composition ================================== \n",
    "    if 'Size' in df_composition.columns:\n",
    "        data_sku = pd.merge(df_color, df_composition[['style_id', 'Fit', 'Composition', 'Size']], how='left', on='style_id')\n",
    "    else:\n",
    "        data_sku = pd.merge(df_color, df_composition[['style_id', 'Fit', 'Composition']], how='left', on='style_id')\n",
    "\n",
    "    \n",
    "    # data_sku = pd.merge( df_color, df_composition[['style_id', 'Fit', 'Composition', 'Size']], how='left', on='style_id')\n",
    "    \n",
    "    df_final = pd.concat([df_final, data_sku], axis=0)\n",
    "    \n",
    "# Join showroom data + df_final\n",
    "    \n",
    "data['style_id'] = data['product_id'].apply( lambda x: x[:-3])\n",
    "data['color_id'] = data['product_id'].apply( lambda x: x[-3:])\n",
    "\n",
    "data_raw = pd.merge(data, df_final[['style_id','color_name', 'Fit', 'Composition', 'Size']], how='left', on='style_id')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um csv\n",
    "colection = 'colection_data.csv'\n",
    "data_raw.to_csv(colection, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
