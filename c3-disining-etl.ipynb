{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "import requests\n",
    "import math\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* coleta os 36 prodcts da vitrini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "# url do site\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "# Request to URL\n",
    "page = requests.get( url, headers=headers )\n",
    "\n",
    "# Beautifullsoup\n",
    "soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "# ===================  Product Data  =================================\n",
    "products = soup.find('ul', class_= 'products-listing small')\n",
    "product_list = products.find_all('article', class_ = 'hm-product-item')\n",
    "\n",
    "# Product_id\n",
    "product_list[0].get('data-articlecode')\n",
    "product_id = [i.get('data-articlecode') for i in product_list]\n",
    "\n",
    "# Product_category\n",
    "product_list[0].get('data-category')\n",
    "product_category = [i.get('data-category') for i in product_list]\n",
    "\n",
    "# product_name\n",
    "product_list = products.find_all('a', class_= 'item-link' )\n",
    "product_list[0].get('title')\n",
    "product_name = [i.get('title') for i in product_list]\n",
    "\n",
    "# product_price\n",
    "product_list = products.find_all('span', class_='price regular')\n",
    "product_price = [i.get_text() for i in product_list]\n",
    "\n",
    "\n",
    "data = pd.DataFrame([ product_id, product_category, product_name, product_price ]).T\n",
    "data.columns = ['product_id','product_category', 'product_name', 'product_price']\n",
    "\n",
    "# scrapy datetime\n",
    "data['scrapy_datetime'] = datetime.now().strftime( '%Y-%m-%d %H:%M:%S:')\n",
    "# #plotar\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1130309005</td>\n",
       "      <td>men_jeans_loose</td>\n",
       "      <td>Baggy Jeans</td>\n",
       "      <td>$ 39.99</td>\n",
       "      <td>2023-10-11 14:00:13:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0985159001</td>\n",
       "      <td>men_jeans_skinny</td>\n",
       "      <td>Skinny Jeans</td>\n",
       "      <td>$ 29.99</td>\n",
       "      <td>2023-10-11 14:00:13:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0979945001</td>\n",
       "      <td>men_jeans_loose</td>\n",
       "      <td>Loose Jeans</td>\n",
       "      <td>$ 39.99</td>\n",
       "      <td>2023-10-11 14:00:13:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1159764002</td>\n",
       "      <td>men_jeans_bootcut</td>\n",
       "      <td>Bootcut Loose Jeans</td>\n",
       "      <td>$ 49.99</td>\n",
       "      <td>2023-10-11 14:00:13:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096385001</td>\n",
       "      <td>men_jeans_loose</td>\n",
       "      <td>Loose Jeans</td>\n",
       "      <td>$ 29.99</td>\n",
       "      <td>2023-10-11 14:00:13:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id   product_category         product_name product_price  \\\n",
       "0  1130309005    men_jeans_loose          Baggy Jeans       $ 39.99   \n",
       "1  0985159001   men_jeans_skinny         Skinny Jeans       $ 29.99   \n",
       "2  0979945001    men_jeans_loose          Loose Jeans       $ 39.99   \n",
       "3  1159764002  men_jeans_bootcut  Bootcut Loose Jeans       $ 49.99   \n",
       "4  1096385001    men_jeans_loose          Loose Jeans       $ 29.99   \n",
       "\n",
       "        scrapy_datetime  \n",
       "0  2023-10-11 14:00:13:  \n",
       "1  2023-10-11 14:00:13:  \n",
       "2  2023-10-11 14:00:13:  \n",
       "3  2023-10-11 14:00:13:  \n",
       "4  2023-10-11 14:00:13:  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection by Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* coleta dos prod sxpecifico entra em cada um e faz as rspagem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product:https://www2.hm.com/en_us/productpage.1130309005.html\n",
      "Color: https://www2.hm.com/en_us/productpage.1130309001.html\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 7 elements, new values have 5 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hallanmiranda/Documents/repos/ds_dev_webscraping/c3-disining-etl.ipynb Célula 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hallanmiranda/Documents/repos/ds_dev_webscraping/c3-disining-etl.ipynb#X16sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m df_composition \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([ df_patter, df_composition], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hallanmiranda/Documents/repos/ds_dev_webscraping/c3-disining-etl.ipynb#X16sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m \u001b[39m# rename columns\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/hallanmiranda/Documents/repos/ds_dev_webscraping/c3-disining-etl.ipynb#X16sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m df_composition\u001b[39m.\u001b[39;49mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mArticle_number\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mComposition\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSize\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mproduct_id\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hallanmiranda/Documents/repos/ds_dev_webscraping/c3-disining-etl.ipynb#X16sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m \u001b[39m# guardo aqui as col  que nao foi prevista \u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/hallanmiranda/Documents/repos/ds_dev_webscraping/c3-disining-etl.ipynb#X16sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m aux \u001b[39m=\u001b[39m aux \u001b[39m+\u001b[39m df_composition\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/Documents/repos/ds_dev_webscraping/venv/lib/python3.9/site-packages/pandas/core/generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   6217\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m-> 6218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[1;32m   6219\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   6220\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/repos/ds_dev_webscraping/venv/lib/python3.9/site-packages/pandas/core/generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 767\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[1;32m    768\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/Documents/repos/ds_dev_webscraping/venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    228\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/Documents/repos/ds_dev_webscraping/venv/lib/python3.9/site-packages/pandas/core/internals/base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 7 elements, new values have 5 elements"
     ]
    }
   ],
   "source": [
    "\n",
    "# Empty DataFrame\n",
    "df_compositions = pd.DataFrame()\n",
    "\n",
    "# cria a lista vazia para colocar as col que nao tenho aqui coletada caso meu novo prod tenha alguma caracteristca que nao peguei no promeiro\n",
    "aux = []\n",
    "df_patter = pd.DataFrame(columns= ['Article number','Composition','Fit','color_id','style_id','Size'])\n",
    "\n",
    "for i in range( len( data ) ):\n",
    "    # url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] + '.html'\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + '1130309005' + '.html'\n",
    "    print(f'product:{url}')\n",
    "\n",
    "    # Requisita essa url do servidor do site H&M\n",
    "    page = requests.get( url, headers=headers )\n",
    "\n",
    "    # Parametro de entrada para o beautifulsoup\n",
    "    soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "    # ========================== Color Name ==============================\n",
    "    product_list = soup.find_all('a', class_='filter-option miniature') \n",
    "    color_name = [i.get('data-color') for i in product_list]\n",
    "\n",
    "    # ========================== product_id ==============================\n",
    "    product_id = [i.get('data-articlecode') for i in product_list]\n",
    "    \n",
    "    # ========================== Ccriando o data frame ====================\n",
    "    df_color = pd.DataFrame([product_id, color_name]).T\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "\n",
    "    for c in range( len( df_color )  ):\n",
    "        url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[c, 'product_id'] + '.html'\n",
    "        print('Color: {}'.format(url))        \n",
    "    \n",
    "        page = requests.get( url, headers=headers )\n",
    "        # Parametro de entrada para o beautifulsoup\n",
    "        soup = BeautifulSoup( page.text, 'html.parser' )\n",
    "\n",
    "        # ==============================  Product  ===========================================\n",
    "        product_element_list = soup.find_all('section', class_='product-name-price')\n",
    "        \n",
    "        all_product_info_color = []\n",
    "        \n",
    "        for product_element in product_element_list:\n",
    "            product_info_color = {}\n",
    "            \n",
    "            # =====================  product_name =================================================\n",
    "            color_element = product_element.find('h1', string= 'Baggy Jeans')    \n",
    "            if color_element:\n",
    "                color = re.search(r'productName = \\'(.*?)\\';', color_element.find_next('script').text.strip()).group(1)\n",
    "                product_info_color['Color_Name'] = color\n",
    "                \n",
    "            # =============================== Product Price  ========================================\n",
    "            price_tag = soup.find('span', class_='price-value')\n",
    "            if price_tag:\n",
    "                price = price_tag.get_text(strip=True)\n",
    "                product_info_color['Price'] = price\n",
    "                \n",
    "            # Adicionar as informações do produto à lista\n",
    "            all_product_info_color.append(product_info_color)\n",
    "            \n",
    "            # criar data frame \n",
    "            df_composition = pd.DataFrame(all_product_info_color)    \n",
    "            \n",
    "            # =============================== Compositiom =======================================\n",
    "        \n",
    "            # Encontrei todos os elementos que representam os produtos\n",
    "            product_elements_list = soup.find_all('div', class_='content pdp-text pdp-content')\n",
    "        \n",
    "            # Inicializei uma lista para armazenar as informações de todos os produtos\n",
    "            all_products_info = []\n",
    "            \n",
    "            for product_element in product_elements_list:\n",
    "                product_info = {}\n",
    "    \n",
    "                # FIT\n",
    "                fit_element = product_element.find('dt', string='Fit')\n",
    "                if fit_element:\n",
    "                    fit = fit_element.find_next('dd').text.strip()\n",
    "                    product_info['Fit'] = fit\n",
    "    \n",
    "                # SIZE\n",
    "                size_element = product_element.find('dt', string='Size')\n",
    "                if size_element:\n",
    "                    size = size_element.find_next('dd').text.strip()\n",
    "                    product_info['Size'] = size    \n",
    "    \n",
    "                # COMPOSITION\n",
    "                composition_element = product_element.find('h3', string='Composition')\n",
    "                if composition_element:\n",
    "                    composition = composition_element.find_next('ul').text.strip()\n",
    "                    composition_cleaned = re.sub(r'(Pocket|lining|Shell)', '', composition, flags=re.IGNORECASE)\n",
    "                    product_info['Composition'] = composition_cleaned.replace('\\n', '')  \n",
    "                \n",
    "                # ARTICLE NUMBER\n",
    "                article_number_element = product_element.find('div', string=re.compile(r'Article number\\d+'))\n",
    "                if article_number_element:\n",
    "                    article_number_text = article_number_element.text.strip()\n",
    "                    article_number = re.search( r'\\d+', article_number_text ).group()\n",
    "                    product_info['Article_number'] =  article_number  \n",
    "    \n",
    "                # Adicionar as informações do produto à lista\n",
    "                all_products_info.append(product_info)\n",
    "    \n",
    "                # criar data frame \n",
    "                df_composition = pd.DataFrame(all_products_info)\n",
    "                \n",
    "                # Garante the same number o columns   (Padrao de dados que eu espero receber) \n",
    "                df_composition = pd.concat([ df_patter, df_composition], axis=0)\n",
    "                \n",
    "                # rename columns\n",
    "                df_composition.columns = ['Article_number', 'Composition', 'Fit', 'Size', 'product_id']\n",
    "                \n",
    "                # guardo aqui as col  que nao foi prevista \n",
    "                aux = aux + df_composition.columns.tolist()\n",
    "                \n",
    "                # merge color + composition  \n",
    "                df_composition = pd.merge( df_composition, df_color, how='left', on='product_id')\n",
    "                \n",
    "                print(df_composition)\n",
    "                \n",
    "                # All product\n",
    "                df_compositions = pd.concat( [df_compositions, df_composition], axis=0)\n",
    "                \n",
    "                \n",
    "                \n",
    "hkkhkhkhkhkhkh   \n",
    "            \n",
    "            \n",
    "                       \n",
    "        #  generate style id+ color id\n",
    "        #  df_color['style_id'] = df_color['product_id'].apply( lambda x: x[:-3] )\n",
    "        #  df_color['color_id'] = df_color['product_id'].apply( lambda x: x[-3:] )\n",
    "    #    \n",
    "        #  df_composition['style_id'] = df_composition['Article number'].apply( lambda x: x[:-3])\n",
    "#     df_composition['color_id'] = df_composition['Article number'].apply( lambda x: x[-3:])\n",
    "    \n",
    "\n",
    "#     # ========================== df_color + df_composition ================================== \n",
    "#     if 'Size' in df_composition.columns:\n",
    "#        data_sku = pd.merge(df_color, df_composition[['style_id', 'Fit', 'Composition', 'Size']], how='left', on='style_id')\n",
    "#     else:\n",
    "#        data_sku = pd.merge(df_color, df_composition[['style_id', 'Fit', 'Composition']], how='left', on='style_id')\n",
    "\n",
    "    \n",
    "#     #data_sku = pd.merge( df_color, df_composition[['style_id', 'Fit', 'Composition','Pocket lining', 'Size']], how='left', on='style_id')\n",
    "    \n",
    "#     df_final = pd.concat([df_final, data_sku], axis=0)\n",
    "    \n",
    "# # Join showroom data + df_final\n",
    "    \n",
    "# data['style_id'] = data['product_id'].apply( lambda x: x[:-3])\n",
    "# data['color_id'] = data['product_id'].apply( lambda x: x[-3:])\n",
    "\n",
    "# data_raw = pd.merge(data, df_final[['style_id','color_name', 'Fit', 'Composition', 'Size']], how='left', on='style_id')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article_number</th>\n",
       "      <th>Composition</th>\n",
       "      <th>Fit</th>\n",
       "      <th>Color_ID</th>\n",
       "      <th>style_id</th>\n",
       "      <th>Size</th>\n",
       "      <th>product_id</th>\n",
       "      <th>color_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1130309001</td>\n",
       "      <td>Denim black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1130309002</td>\n",
       "      <td>Light denim blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The model is 187cm/6'2\" and wears a size 31/32</td>\n",
       "      <td>1130309004</td>\n",
       "      <td>Dark denim gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The model is 187cm/6'2\" and wears a size 31/32</td>\n",
       "      <td>1130309007</td>\n",
       "      <td>Dark denim gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1130309008</td>\n",
       "      <td>Denim red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1130309002</td>\n",
       "      <td>Light denim blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The model is 187cm/6'2\" and wears a size 31/32</td>\n",
       "      <td>1130309004</td>\n",
       "      <td>Dark denim gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The model is 187cm/6'2\" and wears a size 31/32</td>\n",
       "      <td>1130309007</td>\n",
       "      <td>Dark denim gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1130309008</td>\n",
       "      <td>Denim red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cotton 100% Polyester 65%, Cotton 35%</td>\n",
       "      <td>Loose fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The model is 187cm/6'2\" and wears a size 31/32</td>\n",
       "      <td>1130309009</td>\n",
       "      <td>Dark denim blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Article_number                            Composition        Fit Color_ID  \\\n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "..            ...                                    ...        ...      ...   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "0             NaN  Cotton 100% Polyester 65%, Cotton 35%  Loose fit      NaN   \n",
       "\n",
       "   style_id                                            Size  product_id  \\\n",
       "0       NaN                                             NaN  1130309001   \n",
       "0       NaN                                             NaN  1130309002   \n",
       "0       NaN  The model is 187cm/6'2\" and wears a size 31/32  1130309004   \n",
       "0       NaN  The model is 187cm/6'2\" and wears a size 31/32  1130309007   \n",
       "0       NaN                                             NaN  1130309008   \n",
       "..      ...                                             ...         ...   \n",
       "0       NaN                                             NaN  1130309002   \n",
       "0       NaN  The model is 187cm/6'2\" and wears a size 31/32  1130309004   \n",
       "0       NaN  The model is 187cm/6'2\" and wears a size 31/32  1130309007   \n",
       "0       NaN                                             NaN  1130309008   \n",
       "0       NaN  The model is 187cm/6'2\" and wears a size 31/32  1130309009   \n",
       "\n",
       "          color_name  \n",
       "0        Denim black  \n",
       "0   Light denim blue  \n",
       "0    Dark denim gray  \n",
       "0    Dark denim gray  \n",
       "0          Denim red  \n",
       "..               ...  \n",
       "0   Light denim blue  \n",
       "0    Dark denim gray  \n",
       "0    Dark denim gray  \n",
       "0          Denim red  \n",
       "0    Dark denim blue  \n",
       "\n",
       "[216 rows x 8 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'39.99'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_picee = soup.find_all( 'div',  class_=\"primary-row product-item-price\" )\n",
    "product_picee = re.findall(r'\\d+\\.?\\d+', product_picee[0].get_text())[0]git add .\n",
    "git commit -m ''\n",
    "product_picee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* limpeza e separacao dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('./dataset/data_web.csv')\n",
    "# # renomeando as cols\n",
    "# data.rename( columns= lambda x: x.lower(), inplace=True)\n",
    "\n",
    "\n",
    "# # ================================== transfommacao das col ======================================\n",
    "\n",
    "# data = data.dropna(subset=['product_id'])\n",
    "# data['product_id'] = data['product_id'].astype(int)\n",
    "\n",
    "# # product_name\n",
    "# data['product_name'] = data['product_name'].apply(lambda x: x.replace(' ', '_').lower())\n",
    "\n",
    "# # product_price - Remover o símbolo '$' e converter para float\n",
    "# data['product_price'] = data['product_price'].apply(lambda x: x.replace('$', '') if isinstance(x, str) else x ).astype(float)\n",
    "\n",
    "# # scrapy_datetime\n",
    "# data['scrapy_datetime'] = pd.to_datetime(data['scrapy_datetime'], format='%Y-%m-%d %H:%M:%S:')\n",
    "\n",
    "# # Color Name\n",
    "# data['color_name'] = data['color_name'].apply(lambda x: x.replace(' ', '_').replace('/', '_').lower() if isinstance(x, str) else x)\n",
    "\n",
    "# # Fit\n",
    "# data['fit'] = data['fit'].apply(lambda x: x.replace(' ', '_').lower() if isinstance(x, str) else x)\n",
    "\n",
    "# # pocket lining  / Removendo a coluna 'poket lining'\n",
    "\n",
    "# # Size\n",
    "# data['size'] = data['size'].apply(lambda x: x.replace(' ', '_').lower() if isinstance(x, str) else x)\n",
    "\n",
    "# # size_number - Extraido números da coluna 'size'\n",
    "# data['size_number'] = data['size'].apply(lambda x: re.search('\\d{3}cm', x).group(0) if isinstance(x, str) and re.search('\\d{3}cm', x) else x)\n",
    "# data['size_number'] = data['size_number'].apply( lambda x: re.search('\\d+', x).group(0) if pd.notnull( x ) else x )\n",
    "\n",
    "# # size_model - Extraido números da coluna 'size'\n",
    "# data['size_model'] = data['size'].apply( lambda x: re.search('\\d+/\\\\d+', x).group(0) if isinstance(x, str) and re.search('\\d+/\\\\d+', x) else x  )\n",
    "\n",
    "# # ========================== Drop duplicates ==================================================\n",
    "# data = data.drop_duplicates(subset=['product_id', 'product_name', 'product_category', 'product_price','scrapy_datetime', 'style_id', 'color_id', 'color_name', 'fit'], keep='last')\n",
    "\n",
    "# # reset Index\n",
    "# data = data.reset_index(drop=True)\n",
    "\n",
    "# # ========================== brack composition by comma =================================\n",
    "\n",
    "# df1 = data['composition'].str.split(',', expand=True)\n",
    "\n",
    "# #criando um dataframe vazio do tamanho de data para alocar as colunas em ordem\n",
    "# df_ref = pd.DataFrame( index=np.arange( len( data ) ), columns=['cotton', 'Spandex', 'Elastomultiester'] )\n",
    " \n",
    "# # ======= DF Cotton =====================\n",
    "\n",
    "# df_cotton = df1[0] # data que tem só cotton\n",
    "# df_cotton.name = 'cotton' # passo o name para a coluna\n",
    " \n",
    "# df_ref = pd.concat([ df_ref, df_cotton], axis=1) # faco a uniao com concat \n",
    "# df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')] # e dorp a col original q era so NaN\n",
    "\n",
    "# df_ref['cotton'] = df_ref['cotton'].fillna('cotton 0%') # td coton vzio passsa a ser coton 0%\n",
    "\n",
    "# # ============  DF Spandex  =======================\n",
    "\n",
    "# df_spandex = df1.loc[df1[1].str.contains('spandex', na=False), 1]\n",
    "# df_spandex.name = 'spandex'\n",
    "\n",
    "# # combine spandex from brch colum 1 and 2\n",
    "# df_spandex =df_spandex.combine_first( df1[2] )\n",
    "\n",
    "# df_ref = pd.concat([df_ref, df_spandex], axis=1)\n",
    "# df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "# df_ref['spandex'] = df_ref['spandex'].fillna('spandex 0%')\n",
    "\n",
    "# # ================  DF Elastomultiester  ===========================\n",
    "\t\n",
    "# df_Elastomultiester\t = df1.loc[ df1[1].str.contains('Elastomultiester', na=False), 1]\n",
    "# df_Elastomultiester.name = 'Elastomultiester'\n",
    "\n",
    "# df_ref = pd.concat([ df_ref, df_Elastomultiester], axis=1)\n",
    "# df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "# df_ref['Elastomultiester'] = df_ref['Elastomultiester'].fillna('Elastomultiester 0%')\n",
    "\n",
    "# df_ref = df_ref.drop('Spandex', axis=1)\n",
    "\n",
    "# # ========= Concat ================\n",
    "\n",
    "# data = pd.concat([data, df_ref], axis=1)\n",
    "\n",
    "\n",
    "# # =====================  format composition data =====================================\n",
    "\n",
    "# # cotton\n",
    "# data['cotton'] = data['cotton'].apply( lambda x: int( re.search( '\\d+', x ).group(0) ) / 100 if pd.notnull( x ) else x )\n",
    "\n",
    "# #spandex.\n",
    "# data['spandex'] = data['spandex'].apply( lambda x: int( re.search('\\d+', x).group(0) ) /100 if pd.notnull(x) else x )\n",
    "\n",
    "# # Elastomultiester\n",
    "# data['Elastomultiester'] = data['Elastomultiester'].apply( lambda x: int(re.search('\\d+', x).group(0))/ 100 if pd.notnull( x ) else x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ============ Check =================================\n",
    "\n",
    "# data = data.drop( columns=['pocket lining', 'size', 'composition'], axis=1 )\n",
    "# data = data.drop_duplicates()\n",
    "# data.shape\n",
    "\n",
    "\n",
    "# # criando um csv\n",
    "# # dados = 'data_webs_treated.csv'\n",
    "# # data.to_csv(dados, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
